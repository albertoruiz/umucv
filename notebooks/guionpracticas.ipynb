{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesiones prácticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalación de Python + ecosistema científico + opencv + otros paquetes ([install.ipynb](install.ipynb)).\n",
    "\n",
    "- prueba de scripts\n",
    "- manejo básico de jupyter\n",
    "- repaso Python/numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Tutorial del acceso a diferentes fuentes de imágenes con la utilidad `autoStream` de umucv ([captura.ipynb](captura.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Calibración de la cámara (scripts en `code/calibrate`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Script de acceso a los *hand landmarks* de mediapipe (`code/DL/mp_hands/hands.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos de código y utilidades.\n",
    "\n",
    "- `webcam.py` con opencv crudo vs `stream.py`\n",
    "- selección de ROIS (cv.selectROI vs umucv.util.ROI)\n",
    "- Recortar y unir imágenes para conseguir [algo como esto](../images/demos/ej-c0.png).\n",
    "- control de webcam v4l2-ctl, vlc, gucview (`focus.sh`, `power.sh`)\n",
    "- `wzoom.py` (para las ventanas de Windows que no tienen zoom)\n",
    "- `histogram.py`, `histogram2.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medidor de ángulos:\n",
    "- captura de coordenadas: `mouse.py`\n",
    "- círculos en las posiciones marcadas (cv.circle)\n",
    "- coordenadas textuales (cv.putText  (ej. en `hello.py`) o umucv.util.putText)\n",
    "- marcar solo los dos últimos (pista: collections.deque)\n",
    "- reproducir code/medidor.py indicando la distancia en pixels\n",
    "- Dado el FOV: indicar el ángulo de las direcciones marcadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos:\n",
    "- `trackbar.py`, `inrange0.py`, `inrange.py`\n",
    "- `help_window.py`\n",
    "- `save_video.py`\n",
    "\n",
    "Filtros:\n",
    "- Ejemplos de filtros (media, gaussiano, mediana, etc.)\n",
    "- Comparación de la calidad de suavizado y del tiempo de cálculo de un Box Filter vs un filtro Gaussiano (`code/box_vs_gaussian.py`).\n",
    "- Ejercicio de detección de zonas interesantes en la imagen mediante una máscara obtenida como umbralización del promedio local de las diferencias entre cada pixel original y su valor suavizado (`code/boxy.py`).\n",
    "\n",
    "Ejercicio: subir a la carpeta personal del aula virtual un vídeo muy corto (5s) demostrando el funcionamiento del script realizado en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos:\n",
    "\n",
    "- Argumentos en la línea de órdenes coexistiendo con los de autoStream\n",
    "- Detección de actividad: Selección de región y cómputo de la suma de diferencias absolutas respecto al recorte guardado.\n",
    "- Efecto \"fantasmal\" (`code/deque.py`). Reproducirlo actualizando el valor medio con coeficientes $\\alpha$ y $1-alpha$. Crear modelo de fondo con media y desviación típica.\n",
    "- Sustracción de fondo (`code/backsub0.py`, `code/backsub.py`).\n",
    "- Probarlo en vídeo de péndulo\n",
    "- rembg\n",
    "- Segmentador de mediapipe.\n",
    "- Componentes conexas, extracción de contornos (`code/inrange.py`).\n",
    "- Ampliación de `roi.py` para captura de múltiples regiones. Mostrarlas en una ventana seleccionándola con teclas, o todas juntas reescaladas a un número de filas común, usando np.hstack.\n",
    "- Gestos con procrustes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicación del reconocimiento frecuencial de siluetas.\n",
    "- Ejemplo paso a paso en `code/shape/trebol*.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `code/hog/hog0.py`\n",
    "- `code/hog/pedestrian.py`\n",
    "- `code/hog/facelandmarks.py` y efectos especiales.\n",
    "- Captura asíncrona `code/thread`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repaso de *image matching* mediante correlación cruzada (`code/crosscorr.py`)\n",
    "- Demostraciones de detección de movimiento de cámara y de flujo óptico denso.\n",
    "- Detección de *corners* y tracker de Lucas-Kanade (`code/LK`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detector SIFT de OpenCV (`code/SIFT`)\n",
    "- Prueba de concepto de detección de escala con el operador Hessiano (`code/SIFT`).\n",
    "- Uso de nuestros prototipos de visión con el teléfono móvil mediante bots de telegram (`code/bot`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repaso de machine learning\n",
    "- Clasificador de dígitos manuscritos sobre secuencias de imágenes naturales con PCA + modelos gaussianos (`code/DL/CNN`)\n",
    "- Mejora utilizando una red convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualización del paquete umucv: En la raíz del repositorio ejecutamos `pip install package/`\n",
    "\n",
    "- Ejemplos de uso de modelos de deep learning interesantes y sus variantes disponibles en mediapipe (`code/DL`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Demostración de puntos de fuga con coordenadas homogéneas.\n",
    "- Repaso del notebook de transformaciónes del plano (`transf2D.ipynb`).\n",
    "- Ejemplos de rectificación de planos y otras transformaciones relacionadas (\"stitching\", sustitución de cuadrángulos, etc.).\n",
    "- Detección y rectificación de marcador (`code/polygons`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ejemplos de realidad aumentada con marcador artificial (`code/pose`)\n",
    "- Entrenamiento de una U-NET desde cero en un problema muy sencillo (`code/DL/UNET`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ejemplos de reconstruccion 3D\n",
    "- Repaso y dudas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
