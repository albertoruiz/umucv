{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "<img src=\"../images/demos/FIUM.png\" width=\"350px\" class=\"pull-right\" style=\"display: inline-block\">\n",
    "\n",
    "# Visión Artificial\n",
    "\n",
    "### 4º de Grado en Ingeniería Informática\n",
    "\n",
    "Curso 2021-2022<br>\n",
    "Prof. [*Alberto Ruiz*](http://dis.um.es/profesores/alberto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![concept map](../images/demos/concept_map.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [libro de Szeliski](https://szeliski.org/Book/)\n",
    "\n",
    "\n",
    "- [OpenCV](https://opencv.org/), [tutoriales en Python](https://docs.opencv.org/4.1.0/d6/d00/tutorial_py_root.html), [documentación](https://docs.opencv.org/4.1.0/)\n",
    "\n",
    "- [libro](https://books.google.es/books?id=seAgiOfu2EIC&printsec=frontcover)\n",
    "\n",
    "- [libro1](https://books.google.es/books?id=9uVOCwAAQBAJ&printsec=frontcover), [libro2](https://books.google.es/books?id=iNlOCwAAQBAJ&printsec=frontcover)\n",
    "\n",
    "\n",
    "- [Bishop](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)\n",
    "\n",
    "\n",
    "- [scikit-image](http://scikit-image.org/), [scikit-learn](http://scikit-learn.org)\n",
    "\n",
    "\n",
    "- [datasets](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Image_data)\n",
    "\n",
    "\n",
    "- [Python](https://docs.python.org/3.8/)\n",
    "\n",
    "- [numpy](http://www.numpy.org/), [scipy](http://docs.scipy.org/doc/scipy/reference/)\n",
    "\n",
    "- [matplotlib](http://matplotlib.org/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prácticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Preguntas frecuentes](FAQ.ipynb)\n",
    "\n",
    "\n",
    "- [Guión de las sesiones](guionpracticas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Presentación (24/1/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[introducción](intro.ipynb), [instalación](install.ipynb), [Python](python.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introducción a la asignatura\n",
    "\n",
    "- Repaso de Python, numpy y matplotib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introducción a la imagen digital (31/1/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[imagen](imagen.ipynb), [gráficas](graphs.ipynb), [indexado/stacks](stacks.ipynb), [dispositivos de captura](captura.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modelo pinhole. Campo de visión (FOV, *field of view*, parámetro $f$)\n",
    "\n",
    "- Imagen digital: rows, cols, depth, step. Planar or pixel order. Tipo de pixel: byte vs float\n",
    "\n",
    "- Color encoding: RGB vs YUV vs HSV\n",
    "\n",
    "- Coordendas de pixel, coordenadas normalizadas (indep de resolución), coordenadas calibradas (independiente del FOV).\n",
    "\n",
    "- Aspect ratio. Resize.\n",
    "\n",
    "- Manipulación: slice regions, \"stack\" de imágenes\n",
    "\n",
    "- primitivas gráficas\n",
    "\n",
    "- captura: webcams, cameras ip, archivos de vídeo, v4l2-ctl, etc. Load / save.\n",
    "\n",
    "- entornos de conda, pyqtgraph, pycharm, spyder\n",
    "\n",
    "- Herramientas: formatos de imagen, imagemagick, gimp, mplayer/mencoder/ffmpeg, mpv, gstreamer, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Segmentación por color (7/2/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[canales de color](color.ipynb), [histograma](histogram.ipynb), [efecto chroma](chroma.ipynb), [segmentación por color](colorseg.ipynb)\n",
    "<br>\n",
    "[cuantización de color](codebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teoría del color\n",
    "\n",
    "- ROIs, masks, probability map, label map\n",
    "\n",
    "- Componentes conexas vs contornos.\n",
    "\n",
    "- inRange\n",
    "\n",
    "- Chroma key\n",
    "\n",
    "- Histograma, transformaciones de valor (brillo, contraste), ecualización\n",
    "\n",
    "- Histograma nD\n",
    "\n",
    "- Distancia entre histogramas. Reproyección de histograma\n",
    "\n",
    "- background subtraction\n",
    "\n",
    "- activity detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filtros digitales (14/2/22, 21/2/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[filtros de imagen](filtros.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lineal\n",
    "\n",
    "    - convolution\n",
    "    - máscaras para paso alto, bajo, etc.\n",
    "    - separabilidad\n",
    "    - integral image, box filter\n",
    "    - dominio frecuencial\n",
    "    - filtrado inverso\n",
    "\n",
    "\n",
    "- no lineal\n",
    "\n",
    "    - mediana\n",
    "    - min, max\n",
    "    - algoritmos generales\n",
    "\n",
    "\n",
    "- Gaussian filter\n",
    "\n",
    "    - separabilidad\n",
    "    - cascading\n",
    "    - Fourier\n",
    "    - scale space\n",
    "\n",
    "\n",
    "\n",
    "- [morphological operations](http://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html#gsc.tab=0)\n",
    "\n",
    "    - structuring element\n",
    "    - dilate, erode\n",
    "    - open, close\n",
    "    - gradient\n",
    "    - fill holes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Análisis frecuencial  (21/2/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[análisis frecuencial](fourier.ipynb), [filtrado inverso](inversefilt.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5. Detección de bordes (28/2/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[detección de bordes](bordes.ipynb), [Canny nms en C](cannyC.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gradiente: visualización como *vector field*\n",
    "\n",
    "- operador de Canny\n",
    "\n",
    "- transformada de Hough\n",
    "\n",
    "- Histograma de orientaciones del gradiente (HOG)\n",
    "\n",
    "- implementación simple de HOG\n",
    "\n",
    "- detección de *pedestrians*\n",
    "\n",
    "- face landmarks (dlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Flujo óptico (7/3/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[elipse de incertidumbre](covarianza.ipynb), [optical flow](harris.ipynb)\n",
    "\n",
    "- elipse de incertidumbre\n",
    "\n",
    "- cross-correlation\n",
    "\n",
    "- corners (Harris)\n",
    "\n",
    "- Lucas-Kanade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. *Keypoints* (14/3/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[keypoints](keypoints.ipynb), [bag of visual words](bag-of-words.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modelo cuadrático\n",
    "\n",
    "- blobs / saddle points (Hessian)\n",
    "\n",
    "- SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Reconocimiento de formas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[shapes](shapes.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- umbralización\n",
    "\n",
    "- análisis de regiones (componentes conexas, transformada de distancia)\n",
    "\n",
    "- manipulación de contornos\n",
    "\n",
    "- invariantes frecuenciales de forma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. Otras técnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[textura](textura.ipynb), [varios](varios.ipynb), [transformada de distancia](transf-dist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clasificación de texturas mediante *LBP* (Wang and He, 1990, [wiki](https://en.wikipedia.org/wiki/Local_binary_patterns))\n",
    "\n",
    "- Detección de caras mediante *adaboost* ([Viola & Jones, 2001](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.6807), [wiki](https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework))\n",
    "\n",
    "- Herramientas para OCR (*[tesseract](https://github.com/tesseract-ocr)*)\n",
    "\n",
    "- Herramientas para códigos de barras y QR (*[zbar](http://zbar.sourceforge.net/)*)\n",
    "\n",
    "- Segmentación de objetos mediante *GrabCut* ([Rother et al. 2004](https://cvg.ethz.ch/teaching/cvl/2012/grabcut-siggraph04.pdf), [tutorial](http://docs.opencv.org/3.2.0/d8/d83/tutorial_py_grabcut.html))\n",
    "\n",
    "- Transformada de distancia\n",
    "\n",
    "- Detección de elipses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. *Machine learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[machine learning](machine-learning.ipynb)\n",
    "\n",
    "- Repaso de *Machine Learning* y *Pattern Recognition*\n",
    "\n",
    "- Repaso de computación neuronal\n",
    "\n",
    "- Introducción a la redes convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. *Deep learning* en visión artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[modelos avanzados](deep.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modelos preentrenados\n",
    "\n",
    "- YOLO\n",
    "\n",
    "- face recognition\n",
    "\n",
    "- openpose (body landmarks)\n",
    "\n",
    "- Transfer learning\n",
    "\n",
    "- Data augmentation\n",
    "\n",
    "- UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. Coordenadas homogéneas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos el estudio de la geometría visual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[perspectiva](geovis.ipynb), [coordenadas homogéneas](coordhomog.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaciones lineales\n",
    "\n",
    "- espacios lineales, vectores\n",
    "\n",
    "- transformaciones lineales, matrices\n",
    "\n",
    "- producto escalar (**dot** product)\n",
    "\n",
    "- producto vectorial (**cross** product)\n",
    "\n",
    "- puntos, rectas, planos, meet & join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometría del plano\n",
    "\n",
    "- coordenadas homogéneas\n",
    "\n",
    "- interpretación como rayos\n",
    "\n",
    "- puntos y rectas del plano\n",
    "\n",
    "- incidencia e intersección, dualidad\n",
    "\n",
    "- puntos del infinito, recta del infinito\n",
    "\n",
    "- manejo natural de puntos del infinito\n",
    "\n",
    "- horizonte de un plano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. Transformaciones del plano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[transformaciones del plano](transf2D.ipynb), [sistemas de ecuaciones](sistecs.ipynb), [transformaciones de dominio](lookup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desplazamientos, rotaciones, escalado uniforme, escalado general, proyectividad.\n",
    "\n",
    "- Grupos euclídeo, similar, afín, proyectivo.\n",
    "\n",
    "- Propiedades invariantes de cada grupo.\n",
    "\n",
    "- Representación como matriz homogénea $3\\times 3$ y tipos de matriz de cada grupo.\n",
    "\n",
    "- *Cross ratio* de 4 puntos en una recta. De 5 rectas.\n",
    "\n",
    "- Estimación de transformaciones a partir de correspondencias.\n",
    "\n",
    "- Aplicaciones: rectificación de planos, mosaico de imágenes.\n",
    "\n",
    "- Transformaciones de dominio (deformaciones), lookup table.\n",
    "\n",
    "Avanzado\n",
    "\n",
    "- Transformación de rectas. Covarianza y contravarianza.\n",
    "\n",
    "- Cónicas: incidencia, tangencia, (pole-polar), cónica dual, transformación.\n",
    "\n",
    "- Objetos invariantes en cada grupo de transformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. Modelo de cámara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[modelo de la cámara](camera.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Espacio proyectivo: puntos y líneas 3D, planos, grados de libertad, plano del infinito, analogía con 2D.\n",
    "\n",
    "- Grupos de transformaciones 3D: y sus invariantes.\n",
    "\n",
    "- Modelo pinhole (proyección), cámara oscura, lente.\n",
    "\n",
    "- Transformación de perspectiva: proyección $\\mathcal P^3 \\rightarrow\\mathcal P ^2$.\n",
    "\n",
    "- cámara calibrada C=PRT, 6 dof, parámetros extrínsecos o pose.\n",
    "\n",
    "- calibración, distorsión radial.\n",
    "\n",
    "- Matriz de cámara estándar $M=K[R|t]$.\n",
    "\n",
    "- Matriz de calibración $K$ y campo visual.\n",
    "\n",
    "- PnP (*pose from n points*).\n",
    "\n",
    "- Realidad aumentada.\n",
    "\n",
    "- Anatomía de la cámara\n",
    "\n",
    "- Rotaciones sintéticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. Visión estéreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stereo](stereo.ipynb), [stereo-challenge](stereo-challenge.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Triangulación\n",
    "\n",
    "- Geometría epipolar\n",
    "\n",
    "- Extracción de cámaras\n",
    "\n",
    "- Rectificación estéreo\n",
    "\n",
    "- Mapas de profundidad\n",
    "\n",
    "\n",
    "Experimentos\n",
    "\n",
    "- Reproduce los experimentos con un par estéreo tomado con tu propia cámara usando el *tracker* de puntos estudiado en una clase anterior.\n",
    "\n",
    "- Intenta poner en marcha el sistema [VisualSFM](http://ccwu.me/vsfm/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [introducción](intro.ipynb)\n",
    "1. [instalación](install.ipynb)\n",
    "1. [Python](python.ipynb)\n",
    "\n",
    "1. [dispositivos de captura](captura.ipynb)\n",
    "\n",
    "1. [imagen](imagen.ipynb)\n",
    "1. [gráficas](graphs.ipynb)\n",
    "1. [canales de color](color.ipynb)\n",
    "\n",
    "1. [indexado, stacks](stacks.ipynb)\n",
    "1. [histograma](histogram.ipynb)\n",
    "1. [efecto chroma](chroma.ipynb)\n",
    "1. [segmentación por color](colorseg.ipynb)\n",
    "1. [cuantización de color](codebook.ipynb)\n",
    "\n",
    "1. [transformaciones de dominio](lookup.ipynb) \n",
    "\n",
    "1. [filtros de imagen](filtros.ipynb)\n",
    "1. [análisis frecuencial](fourier.ipynb)\n",
    "1. [filtrado inverso](inversefilt.ipynb)\n",
    "\n",
    "1. [transformada de distancia](transf-dist.ipynb)\n",
    "\n",
    "1. [detección de bordes](bordes.ipynb)\n",
    "\n",
    "1. [técnicas auxiliares](ipmisc.ipynb)\n",
    "1. [Canny nms en C](cannyC.ipynb)\n",
    "\n",
    "1. [elipse de incertidumbre](covarianza.ipynb)\n",
    "1. [optical flow](harris.ipynb)\n",
    "\n",
    "1. [keypoints](keypoints.ipynb)\n",
    "1. [bag of visual words](bag-of-words.ipynb)\n",
    "\n",
    "1. [machine learning](machine-learning.ipynb)\n",
    "1. [deep learning](deep.ipynb)\n",
    "1. [tensorflow](tensorflow.ipynb)\n",
    "\n",
    "1. [sistemas de ecuaciones](sistecs.ipynb)\n",
    "\n",
    "1. [textura](textura.ipynb)\n",
    "\n",
    "1. [shapes](shapes.ipynb)\n",
    "\n",
    "1. [varios](varios.ipynb)\n",
    "\n",
    "1. [perspectiva](geovis.ipynb)\n",
    "1. [coordenadas homogéneas](coordhomog.ipynb)\n",
    "1. [transformaciones del plano](transf2D.ipynb)\n",
    "1. [DLT](DLT.ipynb)\n",
    "\n",
    "1. [modelo de cámara](camera.ipynb)\n",
    "\n",
    "1. [visión stereo](stereo.ipynb)\n",
    "1. [stereo-challenge](stereo-challenge.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación inicial\n",
    "\n",
    "1. [`hello.py`](../code/hello.py): lee imagen de archivo, la reescala, muestra y sobreescribe un texto.\n",
    "\n",
    "1. [`webcam.py`](../code/webcam.py): muestra la secuencia de imágenes capturadas por una webcam.\n",
    "\n",
    "1. [`2cams.py`](../code/2cams.py): combina las imágenes tomadas por dos cámaras.\n",
    "\n",
    "1. [`stream.py`](../code/stream.py): ejemplo de uso de la fuente genérica de imágenes.\n",
    "\n",
    "1. [`surface.py`](../code/surface.py): superficie 3D de niveles de gris en vivo usando pyqtgraph.\n",
    "\n",
    "1. [`facemesh.py`](../code/facemesh.py): malla de una cara usando mediapipe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilidades\n",
    "\n",
    "1. [`save_video.py`](../code/save_video.py): ejemplo de uso de la utilidad de grabación de vídeo.\n",
    "\n",
    "1. [`mouse.py`](../code/mouse.py), [`medidor.py`](../code/medidor.py): ejemplo de captura de eventos de ratón.\n",
    "\n",
    "1. [`roi.py`](../code/roi.py): ejemplo de selección de región rectangular.\n",
    "\n",
    "1. [`trackbar.py`](../code/trackbar.py): ejemplo de parámetro interactivo.\n",
    "\n",
    "1. [`help_window.py`](../code/help_window.py): ejemplo de ventana de ayuda.\n",
    "\n",
    "1. [`wzoom.py`](../code/wzoom.py): ejemplo de ventana con zoom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actividad\n",
    "\n",
    "1. [`deque.py`](../code/deque.py): procesamiento de las $n$ imágenes más recientes.\n",
    "\n",
    "1. [`backsub0.py`](../code/backsub0.py), [`backsub.py`](../code/backsub.py): eliminación de fondo mediante MOG2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color\n",
    "\n",
    "1. [`histogram.py`](../code/histogram.py): histograma en vivo con opencv.\n",
    "\n",
    "1. [`histogram2.py`](../code/histogram2.py): histograma en vivo con matplotlib.\n",
    "\n",
    "1. [`inrange0.py`](../code/inrange0.py), [`inrange.py`](../code/inrange.py): umbralización de color, máscaras, componentes conexas y contornos.\n",
    "\n",
    "1. [`reprohist.py`](../code/reprohist.py),  [`mean-shift.py`](../code/mean-shift.py), [`camshift.py`](../code/camshift.py): reproyección de histograma y tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`surface2.py`](../code/surface2.py): superficie 3D de niveles de gris  suavizada y manejo de teclado con pyqtgraph y opengl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`server.py`](../code/server.py): ejemplo de servidor web de imágenes capturadas con la webcam.\n",
    "\n",
    "1. [`mjpegserver.py`](../code/mjpegserver.py): servidor de secuencias de video en formato mjpeg.\n",
    "\n",
    "1. [`bot`](../code/bot): bots de [Telegram](https://python-telegram-bot.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`grabcut.py`](../code/grabcut.py): segmentación de objetos interactiva mediante GrabCut.\n",
    "\n",
    "1. [`spectral.py`](../code/spectral.py): FFT en vivo.\n",
    "\n",
    "1. [`thread`](../code/thread): captura y procesamiento concurrente.\n",
    "\n",
    "1. [`testC.py`](../code/testC.py), [`inC`](../code/inC): Interfaz C-numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`hog/pedestrian.py`](../code/hog/pedestrian.py): detector de peatones de opencv.\n",
    "\n",
    "1. [`hog/facelandmarks.py`](../code/hog/facelandmarks.py): detector de caras y landmarks de dlib.\n",
    "\n",
    "1. [`hog/hog0.py`](../code/hog/hog0.py): experimentos con hog.\n",
    "\n",
    "1. [`regressor.py`](../code/regressor.py): predictor directo de la posición de una región.\n",
    "\n",
    "1. [`crosscorr.py`](../code/crosscorr.py): ejemplo de match template.\n",
    "\n",
    "1. [`kcf.py`](../code/crosscorr.py): ejemplo de discriminative correlation filter.\n",
    "\n",
    "1. [`LK/*.py`](../code/LK): seguimiento de puntos con el método de Lucas-Kanade.\n",
    "\n",
    "1. [`SIFT/*.py`](../code/sift.py): demostración de la detección de keypoints y búsqueda de coincidencias en imágenes en vivo.\n",
    "\n",
    "1. [`shape/*.py`](../code/shape): reconocimiento de formas mediante descriptores frecuenciales.\n",
    "\n",
    "1. [`ocr.py`](../code/ocr.py): reconocimiento de caracteres impresos con tesseract/tesserocr sobre imagen en vivo.\n",
    "\n",
    "1. [`zbardemo.py`](../code/zbardemo.py): detección de códigos de barras y QR sobre imagen en vivo.\n",
    "\n",
    "1. [`code/DL`](../code/DL): Modelos avanzados de deep learning para visión artificial (inception, YOLO, FaceDeep, openpose).\n",
    "\n",
    "1. [`code/polygons`](../code/polygons) y [`code/elipses`](../code/elipses): Rectificación de planos en base a marcadores artificiales.\n",
    "\n",
    "1. [`stitcher.py`](../code/stitcher.py): construcción automática de panoramas.\n",
    "\n",
    "1. [`code/pose`](../code/pose): estimación de la matriz de cámara y realidad aumentada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La entrega de los ejercicios se hará en una tarea del aula virtual dentro de un archivo comprimido.\n",
    "\n",
    "Debe incluir el **código** completo .py de todos los ejercicios, los ficheros auxiliares (siempre que no sean muy pesados), y una **memoria** con una **explicación** detallada de las soluciones propuestas, las funciones o trozos de código más importantes, y **resultados** de funcionamiento con imágenes de evaluación **originales** en forma de pantallazos o videos de demostración. También es conveniente incluir información sobre tiempos de cómputo, limitaciones de las soluciones propuestas y casos de fallo.\n",
    "\n",
    "La memoria se presentará en un formato **pdf** o **jupyter** (en este caso se debe adjuntar también una versión **html** del notebook completamente evaluado).\n",
    "\n",
    "Lo importante, además de la evaluación de la asignatura, es que os quede un buen documento de referencia para el futuro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicios propuestos hasta este momento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obligatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CALIBRACIÓN**. a) Realiza una calibración precisa de tu cámara mediante múltiples imágenes de un *chessboard*. b) Haz una calibración aproximada con un objeto de tamaño conocido y compara con el resultado anterior. c) Determina a qué altura hay que poner la cámara para obtener una vista cenital completa de un campo de baloncesto. d) Haz una aplicación para medir el ángulo que definen dos puntos marcados con el ratón en el imagen. e) Opcional: determina la posición aproximada desde la que se ha tomado una foto a partir ángulos observados respecto a puntos de referencia conocidos. [Más informacion](imagen.ipynb#Calibración)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACTIVIDAD**. Construye un detector de movimiento en una región de interés de la imagen marcada manualmente. Guarda 2 ó 3 segundos de la secuencia detectada en un archivo de vídeo. Opcional: muestra el objeto seleccionado anulando el fondo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLOR**. Construye un clasificador de objetos en base a la similitud de los histogramas de color del ROI (de los 3 canales por separado). [Más información](FAQ.ipynb#Ejercicio-COLOR). Opcional: Segmentación densa por reproyección de histograma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT**. Escribe una aplicación de reconocimiento de objetos (p. ej. carátulas de CD, portadas de libros, cuadros de pintores, etc.) con la webcam basada en el número de coincidencias de *keypoints*. [Más información](FAQ.ipynb#Ejercicio-SIFT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILTROS**. Amplía el código de la práctica 4 para mostrar en vivo el efecto de diferentes filtros, seleccionando con el teclado el filtro deseado y modificando sus parámetros (p.ej. el nivel de suavizado) con trackbars. **a)** Aplica el filtro en un ROI para comparar el resultado con el resto de la imagen ([ejemplo](../images/demos/ej-c4.png)). **b)** Comprueba la propiedad de \"cascading\" del filtro gaussiano. **c)** Comprueba la propiedad de \"separabilidad\" del filtro gaussiano. **d)** Implementa en Python dede cero (usando bucles) el algoritmo de convolución con una máscara general y compara su eficiencia con la versión de OpenCV. **e)** Impleméntalo en C y haz un wrapper para utilizarlo desde Python (consulta al profesor). **f)** Implementa el box filter con la imagen integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VROT**. Amplía el *tracker* de Lucas-Kanade (ejemplo `LK/lk_track.py`) para **a)** determinar en qué dirección se mueve la cámara (UP,DOWN,LEFT,RIGHT, [FORWARD, BACKWARD]); **b)** estimar de forma aproximada la velocidad angular de rotación de la cámara (grados/segundo). [Más información](FAQ.ipynb#Ejercicio-VROT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resto se irá añadiendo a lo largo de las siguientes semanas.\n",
    "\n",
    "Como orientación aquí están los [ejercicios propuestos el curso anterior](ejercicios-curso-anterior.ipynb):"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
