{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios entregables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALIBRACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calibra tu cámara mediante múltiples imágenes de un *chessboard* siguiendo las instrucciones del README en `code/calibrate`. Usa el modo standard o por defecto de la cámara y toma nota de su resolución ($W\\times H$).\n",
    "2. Con el parámetro $f$ obtenido en la calibración, determina el campo visual (FOV, *field of view*) horizontal y vertical.\n",
    "3. Comprueba que estos datos son consistentes con el tamaño de la imagen que obtienes con un objeto de tamaño conocido y situado a una distancia conocida.\n",
    "4. Calcula aproximadamente: a) el tamaño en pixels que tendrá una persona situada a 10m de la cámara. b) A qúe distancia se encuntra un coche que en la imagen tiene 20px del acho.\n",
    "5. Determina a qué altura hay que poner la cámara para obtener una vista cenital completa de un campo de baloncesto.\n",
    "6. Calcula el tamaño en pixels de la pelota cuando está en el suelo.\n",
    "7. Escribe una función que devuelva la altura de la pelota sobre el suelo a partir de su diámetro aparente en pixels.\n",
    "8. Haz una aplicación para medir el ángulo que definen dos puntos marcados con el ratón en la imagen.\n",
    "9. Opcional: determina la posición aproximada desde la que se ha tomado una foto a partir ángulos observados respecto a puntos de referencia conocidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTROS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Muestra en vivo el efecto de diferentes filtros, seleccionando con el teclado el filtro deseado y modificando sus parámetros (p.ej. el nivel de suavizado) con trackbars. Aplica el filtro en un ROI para comparar el resultado con el resto de la imagen ([ejemplo](../images/demos/ej-c4.png)). Diseña el ejercicio de forma que sea fácilmente ampliable.\n",
    "2. Comprueba la propiedad de \"cascading\" del filtro gaussiano.\n",
    "3. Comprueba la propiedad de \"separabilidad\" del filtro gaussiano.\n",
    "6. Implementa el box filter con la imagen integral.\n",
    "4. Implementa en Python dede cero (usando bucles) el algoritmo de convolución con una máscara general y compara su eficiencia con la versión de OpenCV.\n",
    "5. Opcional: Implementa la convolución en C y haz un \"wrapper\" para utilizarlo desde Python (consulta al profesor).\n",
    "6. Opcional: Añade alguna forma cómoda de combinar varios filtros en secuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASIFICADOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una aplicación sencilla de reconocimiento de imágenes. Debe admitir (al menos) dos argumentos:\n",
    "\n",
    "`--models=<directorio>`, la carpeta donde hemos guardado un conjunto de imágenes de objetos o escenas que queremos reconocer.\n",
    "\n",
    "`--method=<nombre>`, el nombre de un método de comparación. \n",
    "\n",
    "Cada fotograma de entrada se compara con los modelos utilizando el método seleccionado y se muestra información sobre el resultado (el modelo más parecido o probable, las distancias a los diferentes modelos, alguna medida de confianza, etc.).\n",
    "\n",
    "1. Diseña la aplicación para que sea cómodo añadir nuevos métodos. Cada método debe implementarse en un módulo diferente con un interfaz común.\n",
    "1. Puedes permitir que se añadan modelos sobre la marcha y dar la opción de salvarlos.\n",
    "1. Precomputa todo lo necesario para cada modelo, para que la comparación sea lo más rápida posible.\n",
    "1. Implementa un método basado en el \"embedding\" obtenido por [mediapipe](https://developers.google.com/mediapipe/solutions/vision/image_embedder) (`code/DL/embbeder`).\n",
    "1. Implementa un reconocedor de gestos de manos basado, por ejemplo, en la distancia procrustes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añade al ejercicio CLASIFICADOR un método basado en el número de coincidencias de keypoints SIFT. Utilízalo para reconocer objetos con bastante textura (p. ej. carátulas de CD, portadas de libros, cuadros de pintores, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena un modelo de deep learning con tus propias imágenes. Puedes utilizar la herramienta [ultralytics](https://docs.ultralytics.com/modes/train/#usage-examples) y apoyarte en el ejemplo `code/DL/yolotrain`. Otra posibilidad es reproducir el ejemplo `code/DL/UNET`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECTIFICACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deshaz la deformación de perspectiva de la imagen de un plano para medir distancias (tomando manualmente referencias conocidas). Por ejemplo, mide la distancia entre las monedas en `coins.png` o la distancia a la que se realiza el disparo en `gol-eder.png`. Las coordenadas reales de los puntos de referencia y sus posiciones en la imagen deben pasarse como parámetro en un archivo de texto. Aunque puedes mostrar la imagen rectificada para comprobar las operaciones, debes marcar los puntos y mostrar el resultado sobre la imagen original. Verifica los resultados con **imágenes originales** tomadas por ti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPCIONALES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Haz un controlador sin contacto de varios grados de libertad que mida, al menos, distancia de la mano a la cámara y ángulo de orientación. Utilízalo para controlar alguno de tus programas.\n",
    "2. Haz un clasificador de trayectorias simples dibujadas con el dedo índice en el aire enfrente de la cámara.\n",
    "3. Haz una implementación propia de un algoritmo de extracción de contornos de una imagen binaria.\n",
    "5. Implementa un procedimiento para mejorar la aproximación poligonal obtenida por el método `cv.approxPolyDP` permitiendo vértices fuera del contorno de entrada. Da una medida de la calidad de la aproximación. Pruébalo construyendo un cuadrilátero a partir de la silueta de un carnet o una tarjeta con las esquinas redondeadas.\n",
    "6. Investiga algún modelo de deep learning para recuperar imágenes desenfocadas (deblurring) y compáralo con el filtro de Wiener en imágenes propias.\n",
    "7. Amplía el tracker de Lucas-Kanade (ejemplo `LK/lk_track.py`) para a) determinar en qué dirección se mueve la cámara (UP, DOWN, LEFT, RIGHT, FORWARD, BACKWARD); b) estimar de forma aproximada la velocidad angular de rotación de la cámara (grados/segundo).\n",
    "1. Haz un programa capaz de rellenar con realidad aumentada un sudoku que se observa en una imagen en vivo.\n",
    "\n",
    "1. Sustituye la foto de tu carnet de la UMU que se observa en una imagen en vivo. Intenta conseguir un resultado parecido a `../images/demos/dni.mp4`.\n",
    "\n",
    "1. Crea automáticamente un mosaico a partir de las imágenes en una carpeta. Las imágenes no tienen por qué estar ordenadas ni formar una cadena lineal y no sabemos el espacio que ocupa el resultado. El usuario debe intervenir lo menos posible. Recuerda que debe tratarse de una escena plana o de una escena cualquiera vista desde el mismo centro de proyección. Debes usar homografías. Compara el resultado con el que obtiene la utilidad de stitching de OpenCV.\n",
    "\n",
    "1. Crea un efecto de realidad aumentada en el que el usuario desplace objetos virtuales hacia posiciones marcadas con el ratón.\n",
    "\n",
    "1. Utiliza [colmap](https://colmap.github.io/) o [meshroom](https://meshroom-manual.readthedocs.io/en/latest/) para construir un modelo 3D de un objeto. Compara con [vggt](https://github.com/facebookresearch/vggt).\n",
    "\n",
    "1. Resuelve un problema de visión artificial de tu elección. Solo se valorarán las aportaciones originales."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
