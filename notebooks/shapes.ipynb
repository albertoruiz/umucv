{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de formas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección estudiaremos el reconocimiento de objetos planos a partir de su silueta. Inicialmente estamos interesados en figuras rígidas observadas con poca inclinación. Al final de la clase seremos capaces de conseguir un resultado parecido al siguiente:\n",
    "\n",
    "![image](https://raw.githubusercontent.com/albertoruiz/umucv/master/images/demos/shapedetect.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema puede descomponerse en varios pasos: binarización, extracción de contornos, extracción de características invariantes y clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas y funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import cv2               as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage             import data\n",
    "from scipy               import ndimage\n",
    "\n",
    "def fig(w,h):\n",
    "    plt.figure(figsize=(w,h))\n",
    "\n",
    "def readrgb(file):\n",
    "    return cv.cvtColor( cv.imread('../images/'+file), cv.COLOR_BGR2RGB) \n",
    "\n",
    "def rgb2gray(x):\n",
    "    return cv.cvtColor(x,cv.COLOR_RGB2GRAY)\n",
    "\n",
    "def imshowg(x):\n",
    "    plt.imshow(x, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para extraer las siluetas construimos una máscara (imagen de valores lógicos) que indican los pixeles que pertenecen a los objetos de interés, separándolos del fondo. El método más sencillo es el **umbralizado**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV proporciona [varios métodos](https://docs.opencv.org/4.7.0/d7/d4d/tutorial_py_thresholding.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagen monocroma de prueba de scipy.ndimage\n",
    "g = data.coins()\n",
    "print(g.shape)\n",
    "imshowg(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta imagen de prueba supone un problema para la binarización, ya que no es fácil encontrar un de gris adecuado para todas las monedas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(g.flatten(), bins=np.arange(257), fc='b', ec='b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umbral fijo, seleccionado de forma **manual**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, gt = cv.threshold(g,75,255,cv.THRESH_BINARY)\n",
    "\n",
    "print(ret)\n",
    "\n",
    "imshowg(gt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "\n",
    "g0 = g\n",
    "\n",
    "def fun(h=128):\n",
    "    imshowg(g0>h);\n",
    "\n",
    "interactive(fun, h=(0,255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umbral **automático** (global para todo el ROI): [método de Otsu](https://en.wikipedia.org/wiki/Otsu%27s_method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, gt = cv.threshold(g,189,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "print(ret)\n",
    "\n",
    "imshowg(gt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, gt = cv.threshold(g[0:150,0:150],189,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "print(ret)\n",
    "\n",
    "imshowg(gt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umbral **adaptativo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = cv.adaptiveThreshold(g,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY,101,-10)\n",
    "\n",
    "imshowg(gt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de contornos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siluetas pueden describirse de forma equivalente pero más compacta mediante su contorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El diseño de un algoritmo de extracción de contornos es un ejercicio muy instructivo. OpenCV proporciona una implementación eficiente: [findContours](https://docs.opencv.org/3.4.1/d3/dc0/group__imgproc__shape.html#ga17ed9f5d79ae97bd4c7cf18403e1689a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours , h = cv.findContours(gt, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "                                          #cv.RETR_CCOMP  , cv.CHAIN_APPROX_NONE\n",
    "                                          #devuelve todos\n",
    "\n",
    "# h  (hierarchy) da información de qué contornos están dentro de otros (útil con cv.RETR_TREE)\n",
    "# contours tiene estructura nx1x2 (con una dimensión superflua !?)\n",
    "\n",
    "print(len(contours))\n",
    "print(contours[10])\n",
    "print(contours[10].shape)\n",
    "\n",
    "for x in contours:\n",
    "    plt.plot(x[:,:,0],x[:,:,1],color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos los que no son muy cortos y redimensionamos su estructura a $n\\times 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = [ x.reshape(-1,2) for x in contours if len(x)> 50 ]\n",
    "\n",
    "print(len(ok))\n",
    "\n",
    "imshowg(g);\n",
    "for c in ok:\n",
    "    x,y = c.T\n",
    "    plt.plot(x,y,'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos en detalle uno de ellos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(6,6)\n",
    "plt.plot(*ok[9].T,'o-'); plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que el primer/último punto no se repite (con un plot simple queda el contorno no se cierra) y que el método de `cv.CHAIN_APPROX_SIMPLE` elimina nodos redundantes en el interior de fragmentos rectos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV proporciona varias funciones para [manipular contornos](https://docs.opencv.org/4.7.0/dd/d49/tutorial_py_contour_features.html):\n",
    "\n",
    "- Área\n",
    "- Perímetro\n",
    "- Convex Hull\n",
    "- Momentos (centroide, elipsoide de incertidumbre)\n",
    "- Reducción de nodos\n",
    "- Bounding box\n",
    "- Relleno de una imagen\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de componentes conexas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un método alternativo para segmentar zonas destacadas en una imagen es obtener las componentes conexas. Se devuelven como una imagen de etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,cc = cv.connectedComponents(gt)\n",
    "print(n)\n",
    "plt.imshow(cc);\n",
    "print(cc.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentamos eliminar las regiones muy pequeñas con operaciones morfológicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv.morphologyEx(gt, cv.MORPH_OPEN, np.zeros([5,5],np.uint8), anchor=(-1,-1))\n",
    "\n",
    "imshowg(opening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de *opening* en `scipy.ndimage` funciona bastante bien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = ndimage.binary_opening(gt)\n",
    "\n",
    "imshowg(opening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos rellenar los agujeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = ndimage.binary_fill_holes(gt)\n",
    "print(gtf.dtype)\n",
    "imshowg(gtf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O combinar ambas operaciones para conseguir una buena colección de regiones candidatas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = ndimage.binary_opening(ndimage.binary_fill_holes(gt))\n",
    "print(gtf.dtype)\n",
    "imshowg(gtf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,cc = cv.connectedComponents(gtf.astype(np.uint8))\n",
    "print(n)\n",
    "plt.imshow(cc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear una máscara booleana para una región concreta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshowg(cc==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una listas de máscaras booleanas para las regiones suficientemente grandes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = [ cc==k for k in range(1,n) if np.sum(cc==k) > 300]\n",
    "len(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshowg(ok[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos extraer cualquier región de la imagen original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(g.shape)\n",
    "np.copyto(res, g, where = ok[0])\n",
    "imshowg(res);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros_like(g)\n",
    "res[ok[0]] = g[ok[0]]\n",
    "imshowg(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede hacer lo mismo borrando donde no esté la figura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = g.copy()\n",
    "res[ok[0]==False] = 0\n",
    "imshowg(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos podemos recortar las regiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = np.argwhere(ok[0])\n",
    "(x1, y1), (x2, y2) = thing.min(0), thing.max(0)\n",
    "\n",
    "box = res[x1:x2+1,y1:y2+1]\n",
    "imshowg(box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo junto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view = readrgb(\"plate.jpg\")\n",
    "view = readrgb(\"contours.png\")\n",
    "print(view.shape)\n",
    "\n",
    "ret, gt = cv.threshold(cv.cvtColor(view,cv.COLOR_RGB2GRAY),100,255,cv.THRESH_BINARY_INV)\n",
    "n,cc = cv.connectedComponents(gt)\n",
    "print(n)\n",
    "ok = [ cc==k for k in range(1,n) ]\n",
    "\n",
    "def sacalo(mask):\n",
    "    thing = np.argwhere(mask)\n",
    "    (x1, y1), (x2, y2) = thing.min(0), thing.max(0)\n",
    "    box = mask[x1:x2+1,y1:y2+1].astype(np.float32)\n",
    "    return box\n",
    "\n",
    "promising = [sacalo(ok[k]) for k in range(1,len(ok))]\n",
    "promising = [ p for p in promising if p.sum() > 100]\n",
    "print(len(promising))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_size(x):\n",
    "    h,w = x.shape[:2]\n",
    "    r = cv.resize(x, (0,0), fx=100/h, fy = 100/h)\n",
    "    return np.pad(r,10,mode='constant',constant_values=0)\n",
    "\n",
    "fig(12,8)\n",
    "imshowg(np.hstack([normalize_size(x) for x in promising]))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe una variante que proporciona el bounding box, área y centro, [connected components with stats](https://docs.opencv.org/3.0-beta/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html#connectedcomponents). Tenemos un ejemplo de uso en `inrange.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funcionalidad que podemos conseguir con las componentes conexas es similar a la que proporcionan los contornos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Maximally Stable Extremal Regions](https://en.wikipedia.org/wiki/Maximally_stable_extremal_regions)* es otro método para encontrar regiones destacadas. Se basa en encontrar los diferentes umbrales de binarización cuyo cambio produce el menor cambio de área en cada zona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mser = cv.MSER_create()\n",
    "#regs = mser.detectRegions(g, bboxes=None)\n",
    "regs,_ = mser.detectRegions(g)\n",
    "\n",
    "# devuelve \"conjuntos\" de puntos, nx2, \n",
    "# (no contornos (silueta), ni imagen de etiquetas)\n",
    "# El segundo resultado es una lista de rectángulos (bounding boxes)\n",
    "\n",
    "# dibujar con plot todos los puntos es lento\n",
    "imshowg(g*0);\n",
    "for x in regs:\n",
    "    plt.plot(x[:,0],x[:,1],'.y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es más rápido rellenar una imagen vacía con los puntos obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros_like(g)\n",
    "for p in regs:\n",
    "    x,y = p.T\n",
    "    res[y,x] = 255\n",
    "plt.imshow(res); plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos permite obtener los contornos con `findContours`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts,_ = cv.findContours(res,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "for x in conts:\n",
    "    plt.plot(x[:,:,0],x[:,:,1],color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignando el mismo valor a todos perdemos los posibles contornos internos. Otra posibilidad es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros_like(g)\n",
    "for k, p in enumerate(regs):\n",
    "    x,y = p.T\n",
    "    res[y,x] = (k+1) % 256\n",
    "\n",
    "plt.imshow(res);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts,_ = cv.findContours(res,cv.RETR_CCOMP,cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for x in conts:\n",
    "    plt.plot(x[:,:,0],x[:,:,1],color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Es posible también extraer las regiones MSER en forma de *keypoint* con `mser.detect`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los MSER pueden no ser disjuntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regiones convexas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pueden extraerse mediante la [transformada de distancia](transf-dist.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidades\n",
    "\n",
    "Una vez vistos diferentes métodos de segmentación de regiones, vamos a definir funciones para extraer y representar contornos de forma cómoda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractContours(g, minlen=50, holes=False):\n",
    "    if holes:\n",
    "        mode = cv.RETR_CCOMP\n",
    "    else:\n",
    "        mode = cv.RETR_EXTERNAL\n",
    "    gt = cv.adaptiveThreshold(g,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY,101,-10)\n",
    "    contours,_ = cv.findContours(gt, mode ,cv.CHAIN_APPROX_NONE)\n",
    "    ok = [c.reshape(len(c),2) for c in contours if cv.arcLength(c,closed=True) >= minlen]\n",
    "    ok = sorted(ok, key=cv.contourArea, reverse=True)\n",
    "    return ok\n",
    "\n",
    "def shcont(c, col='b', nodes=False, flipy = False):\n",
    "    x = c[:,0]\n",
    "    y = c[:,1]\n",
    "    if flipy: y = - y\n",
    "    x = np.append(x,x[0])\n",
    "    y = np.append(y,y[0])\n",
    "    plt.plot(x,y,col)\n",
    "    if nodes:\n",
    "        plt.plot(x,y,col+'.',markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducción de nodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunas aplicaciones puede interesar una representación compacta de los contornos reduciendo los vértices \"redundantes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 255 - rgb2gray(readrgb('contours.png'))\n",
    "\n",
    "conts = extractContours(g)\n",
    "\n",
    "red = cv.approxPolyDP(conts[1],0.9,True)\n",
    "red = red.reshape(red.shape[0],2)\n",
    "\n",
    "print(red.shape)\n",
    "\n",
    "shcont(red,nodes=True)\n",
    "plt.axis('equal'); plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun2(m=1,eps=1.0):\n",
    "    r = cv.approxPolyDP(conts[m],eps,True)\n",
    "    r = r.reshape(-1,2)\n",
    "    shcont(r,nodes=True)\n",
    "    shcont(conts[m],'g')\n",
    "    plt.axis('equal'); plt.axis('off');\n",
    "\n",
    "\n",
    "interactive(fun2, m=(0,len(conts)-1), eps=(0.0,5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ciertos casos es posible detectar cierto tipo de figuras (p.ej. cuadriláteros) si el número de nodos de la versión reducida con una tolerancia adecuada es el correcto, pero como los vértices suelen suavizarse en la imagen los vértices resultantes no son muy precisos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de siluetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente llegamos a nuestro principal objetivo: reconocer formas mediante **descriptores invariantes**. Inicialmente nos interesa invarianza frente a cambios de\n",
    "\n",
    "- posición\n",
    "- tamaño\n",
    "- giro\n",
    "- ruido\n",
    "- resolución de la imagen\n",
    "\n",
    "En primer lugar vamos capturar unos cuantos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invertimos la imagen porque el detector de contornos busca regiones claras (~True) sobre fondo oscuro\n",
    "# pero las letras son negras\n",
    "g = 255-rgb2gray(readrgb('shapes/AZ.png'))\n",
    "\n",
    "g = ndimage.binary_dilation(g).astype(np.uint8)*255\n",
    "\n",
    "fig(18,4)\n",
    "imshowg(g); ax = plt.axis('off');\n",
    "for x in extractContours(g):\n",
    "    shcont(x,'r')\n",
    "plt.axis(ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Los hemos engordado un poco con una operación morfológica de dilatación para que se parezcan un poco más a las letras que usaremos después.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener cuidado porque pueden llegar desordenados. Vamos a ordenarlos de izquierda a derecha (de acuerdo con la coordenada x del primer punto), para poder asociar etiquetas a cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = sorted(extractContours(g), key=lambda x: x[0,0])\n",
    "labels = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "for x in models[0:5]:\n",
    "    plt.plot(x[:,0],-x[:,1],'r')\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar descriptores de forma frecuenciales. En el tema de análisis frecuencial vimos que cualquier función puede expresarse como una suma de senos y cosenos. Cuando el contorno de una figura se representa como una señal compleja estas componentes tienen una interpretación directa como \"órbitas\", como se ilustra en la siguientes animaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video src=\"https://raw.githubusercontent.com/albertoruiz/umucv/master/images/demos/efe.mp4\" controls>efe</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video src=\"https://raw.githubusercontent.com/albertoruiz/umucv/master/images/demos/trebol.mp4\" controls>trébol</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura siguiente se muestran las componentes dominantes situadas en el centro. Cada elipse es la combinación de los círculos de frecuencia k y -k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![components](https://raw.githubusercontent.com/albertoruiz/umucv/master/images/demos/full-components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura anterior las componentes más interesantes para distinguir la forma se ven muy pequeñas. Vamos a quitar la primera, que normalmente es una elipse que engloba toda figura, y multiplicamos por 5 el tamaño de las frecuencias siguientes, que son las que realmente determinan la forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![components](https://raw.githubusercontent.com/albertoruiz/umucv/master/images/demos/shape-components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas componentes frecuenciales son una especie de firma característica de la silueta. Los tamaños relativos de estas elipses permiten construir un descriptor de forma invariante a posición, tamaño, orientación, punto de partida en el muestreo, y ruido de medida (tomando las frecuencias bajas, para descartar detalles de tamaño pequeño)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos interactivamente un suavizado frecuencial de las siluetas, para hacernos una idea de cuántas componentes necesita el descriptor para distinguir aceptablemente los modelos de nuestro problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.fft as fft\n",
    "\n",
    "def smooth(w,c):\n",
    "    z = c[:,0]+c[:,1]*1j # convertimos 2D a 1D complejo\n",
    "    f  = fft.fft(z)      # calculamos la descomposición frecuencial\n",
    "    f[w+1:-w] = 0        # quitamos las frecuencias mayores que w \n",
    "    ccs = fft.ifft(f)    # reconstruimos la señal\n",
    "    return np.vstack([np.real(ccs),np.imag(ccs)]).transpose() # reconvertimos los números complejos a pares x,y\n",
    "\n",
    "\n",
    "def fun3(m=4,w=5):\n",
    "    s = smooth(w,models[m])\n",
    "    plt.plot(s[:,0],-s[:,1]); plt.axis('equal');\n",
    "\n",
    "interactive(fun3, m=(0,len(models)-1), w=(0,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parece necesario conservar frecuencias mucho más altas que 10.\n",
    "\n",
    "El invariante frecuencial de un contorno puede definirse así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invar(c, wmax=10):\n",
    "    x,y = c.T\n",
    "    z = x+y*1j\n",
    "    f  = fft.fft(z)\n",
    "    fa = abs(f)                     # para conseguir invarianza a rotación \n",
    "                                    # y punto de partida\n",
    "    s = fa[1] + fa[-1]              # el tamaño global de la figura para normalizar la escala\n",
    "    v = np.zeros(2*wmax+1)          # espacio para el resultado\n",
    "    v[:wmax] = fa[2:wmax+2];        # cogemos las componentes de baja frecuencia, positivas\n",
    "    v[wmax:] = fa[-wmax-1:];        # y negativas. Añadimos también la frecuencia -1, que tiene\n",
    "                                    # que ver con la \"redondez\" global de la figura\n",
    "\n",
    "    if fa[-1] > fa[1]:              # normalizamos el sentido de recorrido\n",
    "        v[:-1] = v[-2::-1]\n",
    "        v[-1] = fa[1]\n",
    "\n",
    "    return v / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que descriptor es realmente invariante a posición, tamaño, orientación, punto de partida y sentido de recorrido en el muestreo y ruido. (Y diferente en los distintos modelos.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invar(models[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "invar(np.flipud(3*np.roll(models[0],37,0)+np.array([[100,200]])),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora capturamos los contornos de la escena que nos interesa reconocer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = readrgb('contours.png')\n",
    "\n",
    "g = 255-rgb2gray(img)\n",
    "things = extractContours(g,holes=False)\n",
    "\n",
    "imshowg(g); ax = plt.axis('off');\n",
    "for x in things:\n",
    "    shcont(x,'r')\n",
    "plt.axis(ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar la clasificación construimos una función que compara un vector con un conjunto de modelos y devuelve ordenadas las distancias y la correspondiente etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mindist(c,mods,labs):\n",
    "    import numpy.linalg as la\n",
    "    ds = [(la.norm(c-mods[m]),labs[m]) for m in range(len(mods)) ]\n",
    "    return sorted(ds, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probamos con uno de los contornos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = things[1]\n",
    "shcont(x); plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [invar(m) for m in models]\n",
    "\n",
    "mindist(invar(x),feats,labels)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ya con toda la imagen, mostrando solo las manchas que se clasifican aceptablemente bien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(12,8)\n",
    "plt.imshow(img)\n",
    "for x in things:\n",
    "    d,l = mindist(invar(x),feats,labels)[0]\n",
    "    if d < 0.2:\n",
    "        cx,cy = np.mean(x,0)\n",
    "        plt.text(cx,cy,l,color='red',fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que se trata de una vista en perspectiva, más compleja que un cambio de tamaño y rotación. Por tanto, hay que aumentar la tolerancia en la distancia entre descriptores, lo que produce \"falsos positivos\". Si queremos evitarlos perderíamos detecciones correctas.\n",
    "\n",
    "Algunos falsos positivos se podrían evitar eliminando de antemano contornos muy grandes o muy pequeños, o que tocan con los límites de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos otros ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = readrgb('letras.png')[50:260,80:520];  g = rgb2gray(img)\n",
    "#img = readrgb('goldstein.jpg'); g = 255 - rgb2gray(img)\n",
    "img = cv.resize(readrgb('penrose.jpg'),(0,0),fx=0.5,fy=0.5); g = rgb2gray(img)\n",
    "\n",
    "things = extractContours(g,holes=False,minlen=50)\n",
    "\n",
    "fig(12,8)\n",
    "imshowg(g); ax = plt.axis();\n",
    "for x in things:\n",
    "    shcont(x,'r')\n",
    "plt.axis(ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(8,12)\n",
    "plt.imshow(img); plt.axis('off');\n",
    "for x in things:\n",
    "    d,l = mindist(invar(x),feats,labels)[0]\n",
    "    if d < 0.2:\n",
    "        cx,cy = np.mean(x,0)\n",
    "        plt.text(cx,cy,l,color='red',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pueden producirse fallos causados por un tipo de letra distinto al de los modelos, por deformaciones de perspectiva y por fallos de detección, al quedarse letras pegadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La invarianza a inclinación moderada (en condiciones de perspectiva débil, que estudiaremos en una clase posterior) se consigue mediante la transformación de *whitening*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capacidad de discriminación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos gráficamente los vectores invariantes de los palos de la baraja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suits = ['../images/shapes/{}.png'.format(s) for s in 'trebol pica corazon diamante'.split()]\n",
    "fig(6,6)\n",
    "for f in suits:\n",
    "    img = readrgb(f)\n",
    "    g = 255-rgb2gray(img)\n",
    "    c = extractContours(g)[0]\n",
    "    x,y = c.T\n",
    "    plt.plot(x,-y)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(12,4)\n",
    "for f in suits:\n",
    "    img = readrgb(f)\n",
    "    g = 255-rgb2gray(img)\n",
    "    c = extractContours(g)[0]\n",
    "    v = invar(c)\n",
    "    plt.plot( v, label=f.split('/')[-1][:-4])\n",
    "\n",
    "plt.legend();\n",
    "plt.grid()\n",
    "plt.xticks(np.arange(21),list(range(2,12))+list(range(-11,0)));\n",
    "plt.title('invariantes frecuenciales');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio parecen distinguibles sin necesidad de usar frecuencias muy altas. Pero habría que hacer un estudio más cuidadoso teniendo en cuenta las condiciones reales de trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para preparar las animaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc\n",
    "rc('animation', html='html5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAnimation(c, video=True):\n",
    "    global track\n",
    "    c = c / (c.max(axis=0)-c.min(axis=0)).max() *1.5\n",
    "    z = c[:,0]-c[:,1]*1j\n",
    "    f  = fft.fft(z)\n",
    "\n",
    "    def ellip(w):\n",
    "        nf = np.zeros_like(f)\n",
    "        nf[[-w,w]] = f[[-w,w]]\n",
    "        z = fft.ifft(nf)\n",
    "        return np.array([np.real(z), np.imag(z)])[:,:1+len(f)//w]\n",
    "\n",
    "    def pos(t,w):\n",
    "        z = (f[w]*np.exp(2*np.pi*w*t*1j) + f[-w]*np.exp(-2*np.pi*w*t*1j))/len(c)\n",
    "        return np.array([[np.real(z)], [np.imag(z)]])\n",
    "\n",
    "    def upto(t,w):\n",
    "        return sum([pos(t,x) for x in range(1,1+w)])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "    ax.set_xlim(( -1,1))\n",
    "    ax.set_ylim((-1,1))\n",
    "    plt.axis('off')\n",
    "    if video:\n",
    "        plt.close()\n",
    "\n",
    "    track = []\n",
    "\n",
    "    [line0] = ax.plot([],[],color='green',lw=3)\n",
    "\n",
    "    lines = [ax.plot([],[],color='gray',lw=2)[0] for k in range(1,8+1)]\n",
    "\n",
    "    [point1] = ax.plot(*(upto(0,1)),'.', color='gray', markersize=16) \n",
    "    [point2] = ax.plot(*(upto(0,2)),'.', color='gray', markersize=13) \n",
    "    [point3] = ax.plot(*(upto(0,3)),'.', color='gray', markersize=10) \n",
    "\n",
    "    [point] = ax.plot(*(upto(0,8)),'.',markersize=15)\n",
    "\n",
    "    e1 = np.hstack([ellip(1),ellip(1)[:,[0]]])\n",
    "    lines[0].set_data(*e1)\n",
    "\n",
    "    def fotogram(n):\n",
    "        global track\n",
    "        t = n/400\n",
    "\n",
    "        if n==401:\n",
    "            track = []\n",
    "        if n>400:\n",
    "            wmax = 9\n",
    "        else:\n",
    "            wmax = 3\n",
    "\n",
    "        for k,l in enumerate(lines[1:wmax]):\n",
    "            l.set_data(*upto(t,k+1)+ellip(k+2))\n",
    "\n",
    "        point1.set_data(*upto(t,1))\n",
    "        point2.set_data(*upto(t,2))\n",
    "        point3.set_data(*upto(t,3))\n",
    "\n",
    "        track.append(upto(t,wmax)) \n",
    "        line0.set_data(*np.array(track).T)\n",
    "        point.set_data(*upto(t,wmax))\n",
    "        return ()\n",
    "\n",
    "    if video:\n",
    "        def create(frames,interval):\n",
    "            return animation.FuncAnimation(fig, fotogram, frames=frames, interval=interval, blit=True, repeat=False)\n",
    "        return create\n",
    "    else:\n",
    "        fig.canvas.toolbar_visible = False\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.canvas.footer_visible = False\n",
    "        fig.canvas.capture_scroll = False\n",
    "\n",
    "        import time\n",
    "        def play(n):\n",
    "            global track\n",
    "            track = []\n",
    "            for k in range(n):\n",
    "                fotogram(k)\n",
    "                fig.canvas.draw()\n",
    "                time.sleep(0.01)\n",
    "\n",
    "        return play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "create = makeAnimation(models[5])\n",
    "create(frames=80, interval=1000/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# play = makeAnimation(models[5], video=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {
    "5e34d10173ab45d1b2bcbb8b3c7699cd": {
     "views": [
      {
       "cell_index": 72
      }
     ]
    },
    "6086371ef3d9490d8d3c362ba1bfb9a6": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "f3450158fba54214826e906dcbc98c74": {
     "views": [
      {
       "cell_index": 63
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
