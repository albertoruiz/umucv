{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flujo óptico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El [flujo óptico](https://en.wikipedia.org/wiki/Optical_flow) es el movimiento aparente de los elementos de una imagen (puntos, bordes, etc.) debido al movimiento del observador o la escena. Informalmente, es un campo vectorial que indica el movimiento de cada \"pixel\" respecto al fotograma anterior.\n",
    "\n",
    "En este capítulo estudiaremos un método eficiente de estimación del flujo óptico. Necesitaremos dos conceptos previos: la *correlación* cruzada y la matriz de *covarianza* de un conjunto de vectores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2   as cv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def fig(w,h):\n",
    "    plt.figure(figsize=(w,h))\n",
    "\n",
    "def rgb2gray(x):\n",
    "    return cv.cvtColor(x,cv.COLOR_RGB2GRAY)\n",
    "\n",
    "def gray2float(x):\n",
    "    return x.astype(float) / 255\n",
    "\n",
    "def readrgb(file):\n",
    "    return cv.cvtColor( cv.imread(\"../images/\"+file), cv.COLOR_BGR2RGB) \n",
    "\n",
    "import glob\n",
    "\n",
    "def readfiles(path):\n",
    "    return [readrgb(file) for file in sorted(glob.glob('../images/'+path))]\n",
    "\n",
    "def resizeS(s,x):\n",
    "    return cv.resize(x,(0,0), fx = s, fy = s)\n",
    "\n",
    "def gaussian(s,x):\n",
    "    return s * cv.GaussianBlur(x,(0,0), s)\n",
    "\n",
    "def grad(x):\n",
    "    gx = cv.Sobel(x,-1,1,0)\n",
    "    gy = cv.Sobel(x,-1,0,1)\n",
    "    return gx,gy\n",
    "\n",
    "# para ver imágenes monocromas autoescalando el rango\n",
    "def imshowg(x):\n",
    "    plt.imshow(x, 'gray')\n",
    "\n",
    "# para ver imágenes monocromas de float con rango fijo\n",
    "def imshowf(x):\n",
    "    plt.imshow(x, 'gray', vmin = 0, vmax=1)\n",
    "\n",
    "# para ver imágenes con signo\n",
    "def imshows(x,r=1):\n",
    "    plt.imshow(x, 'gray', vmin = -r, vmax=r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mostrar el gradiente como un campo de vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dom(sz, by=1):\n",
    "    r,c = sz\n",
    "    x,y = np.meshgrid(range(0,c,by),range(0,r,by))\n",
    "    return x,y\n",
    "\n",
    "def showgradient(x):\n",
    "    gx,gy = grad(x)\n",
    "    c1,r1 = dom(x.shape)\n",
    "    r2 = -gy[r1,c1]   # filas = - eje Y\n",
    "    c2 =  gx[r1,c1]\n",
    "    plt.quiver(c1, r1, c2, r2, color='green', width=0.002, scale=1, scale_units='xy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para dibujar la elipse de incertidumbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cir = np.array([ [np.cos(t), np.sin(t)] for t in np.linspace(0,2*np.pi, 40) ])\n",
    "\n",
    "def rot(a):\n",
    "    c = np.cos(a)\n",
    "    s = np.sin(a)\n",
    "    return np.array([[c,-s],\n",
    "                     [s, c]])\n",
    "\n",
    "def ellip(mx,my,s1,s2,a):\n",
    "    return np.array([mx,my]) + cir @ np.diag([s1,s2]) @ rot(-a)\n",
    "\n",
    "def uncer_ellipse(x,d=2):\n",
    "    m = np.mean(x,axis=0)\n",
    "    c = np.cov(x,rowvar=False)\n",
    "    l,v = np.linalg.eigh(c)\n",
    "    sl1 = np.sqrt(l[0])\n",
    "    sl2 = np.sqrt(l[1])\n",
    "    v1 = v[:,0]\n",
    "    v2 = v[:,1]\n",
    "    e = ellip(m[0],m[1],d*sl2,d*sl1,np.arctan2(v2[1],v2[0]))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localización mediante *cross-correlation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un método especialmente simple de detección de objetos consiste comparar directamente los valores de pixel del modelo con los de la imagen en todas las posibles localizaciones (*template matching*). Para añadir una cierta invarianza a brillo y contraste es conveniente utilizar la [correlación](https://en.wikipedia.org/wiki/Cross-correlation) como medida de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = readfiles('../images/ccorr/scenes/*.png')\n",
    "mods = readfiles('../images/ccorr/models/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[3]\n",
    "mod = resizeS(1,mods[0])\n",
    "\n",
    "fig(12,4)\n",
    "plt.subplot(1,2,1); plt.imshow(img)\n",
    "plt.subplot(1,2,2); plt.imshow(mod);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = cv.matchTemplate(img,mod,cv.TM_CCORR_NORMED)\n",
    "mr,mc = divmod(cc.argmax(),cc.shape[1])\n",
    "\n",
    "plt.title('max corr: {:.02f} at ({},{})'.format(cc.max(),mr,mc))\n",
    "plt.imshow(cc,'gray');\n",
    "plt.plot([mc],[mr],'.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr,tc = mod.shape[:2]\n",
    "plt.imshow(img); ax = plt.axis();\n",
    "plt.plot([mc,mc+tc,mc+tc,mc,mc],[mr,mr,mr+tr,mr+tr,mr],'g'); plt.axis(ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correlación cruzada es una operación muy parecida a la convolución y puede implementarse de forma eficiente en el dominio de la frecuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script `code/crosscorr.py` hace una demostración de este método con la webcam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Múltiples escalas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La detección multiescala implica repetir el proceso anterior sobre una [pirámide][1] de imágenes reescaladas a tamaños progresivamente menores.\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Pyramid_(image_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosscorr(x,t):\n",
    "    cc = cv.matchTemplate(x,t,cv.TM_CCORR_NORMED)\n",
    "    v = cc.max()\n",
    "    mr,mc = divmod(cc.argmax(),cc.shape[1])\n",
    "    tr,tc = t.shape[:2]\n",
    "    roi = ([mc,mc+tc,mc+tc,mc,   mc],\n",
    "           [mr,mr,   mr+tr,mr+tr,mr])\n",
    "    return v,roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyr(x):\n",
    "    return [ resizeS(s,x) for s in [0.8**k for k in range(-3,6)]]\n",
    "\n",
    "def best(x,t):\n",
    "    can = [ (crosscorr(sx,t), sx) for sx in pyr(x) if all(np.array(sx.shape) >= np.array(t.shape))]\n",
    "    return max(can)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = mods[1]\n",
    "img = imgs[1]\n",
    "\n",
    "(v, (x,y)), s =  best(img,mod)\n",
    "print(v)\n",
    "\n",
    "plt.imshow(s); ax = plt.axis();\n",
    "plt.plot(x,y,'green')\n",
    "plt.axis(ax); plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad la correlación es un método frágil, que solo tiene éxito para detectar objetos rígidos en orientación fija y en escenas controladas.\n",
    "\n",
    "Sin embargo, proporciona un marco conceptual muy útil para abordar la detección de fragmentos elementales de imagen localizables con precisión cuando la escena sufre pequeños movimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Correlation Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Presentación de Matas](https://www.ipta-conference.com/ipta16/images/matas-2016.12.12-ipta-oulu.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de esquinas (corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitivamente, las zonas de la imagen aproximadamente constantes son similares a sí mismas cuando se desplazan en cualquier dirección. Los bordes más o menos rectos son similares en la dirección perpendicular. Estos dos tipos de zonas son ambiguas para nuestros actuales propósitos y podemos descartarlas. En cambio, las zonas de \"esquina\" (*[corners](https://en.wikipedia.org/wiki/Corner_detection)*), donde hay bordes con mucha curvatura, sí pueden localizarse con precisión ya que un pequeño desplazamiento en cualquier dirección produce una gran diferencia entre los pixels correspondientes.\n",
    "\n",
    "La detección de este tipo de zonas con buena localización espacial puede hacerse de forma eficiente mediante el [método de Harris](https://en.wikipedia.org/wiki/Harris_Corner_Detector), basado en la distribución local del gradiente. Puede demostrarse que la localización de un fragmento de imagen por cross-correlation tendrá mayor éxito cuanto mayor sea el \"grosor\" de su \"tensor de estructura\". En la práctica buscamos zonas en las que el gradiente tenga al menos dos direcciones destacadas. Esto ocurre cuando su [elipse de incertidumbre](covarianza.ipynb) tiene un eje menor relativamente grande. (Los ejes de la elipse son las [direcciones principales](https://en.wikipedia.org/wiki/Principal_component_analysis) de la distribución y, matemáticamente corresponden a los [autovalores](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix) de la matriz de covarianza.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = readrgb('pano/pano001.jpg')\n",
    "x = gray2float(rgb2gray(img))\n",
    "\n",
    "plt.imshow(x,'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el gradiente ampliando una zona y consideremos los puntos A,B y C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "trozo = x[120:150,110:160]\n",
    "\n",
    "fig(16,14)\n",
    "plt.imshow(trozo,'gray',vmin=0,vmax=1)\n",
    "showgradient(trozo)\n",
    "#plt.imshow(gx,'coolwarm',vmin=-128,vmax=128)\n",
    "\n",
    "plt.text(10,7,'A',color='red'); plt.text(20,15,'B',color='red'); plt.text(8,18,'C',color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dibujar las \"puntas de flecha\" de los gradientes en un entorno de cada punto (con la base en ese punto). Es una forma de mostrar la distribución local del gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "gx,gy = grad(trozo)\n",
    "\n",
    "def estructura(i,j,n):\n",
    "    dx = gx[i-n:i+n,j-n:j+n].flatten()\n",
    "    dy = -gy[i-n:i+n,j-n:j+n].flatten()\n",
    "    plt.plot(dx,dy,'.')\n",
    "    plt.plot(*uncer_ellipse(np.array([dx,dy]).T).T,lw=3)\n",
    "\n",
    "fig(5*3,4);\n",
    "\n",
    "plt.subplot(1,3,1);\n",
    "estructura(7,10,5); plt.axis([-1,1,-1,1]);\n",
    "plt.title('pixel A: zona plana')\n",
    "\n",
    "plt.subplot(1,3,2);\n",
    "estructura(20,15,5); plt.axis([-1,1,-1,1]);\n",
    "plt.title('pixel B: borde')\n",
    "\n",
    "plt.subplot(1,3,3);\n",
    "estructura(18,8,5); plt.axis([-1,1,-1,1]);\n",
    "plt.title('pixel C: esquina');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada tipo de punto (zonas planas, bordes, esquinas) tiene una distribución de gradiente muy distinta, que podemos caracterizar por el tamaño de los ejes de la elipse de incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a la imagen completa. Vamos a calcular el eje menor de la elipse de incertidumbre en cada punto. Para ello necesitamos la matriz de covarianza. Por sencillez consideramos la distribución centrada en el origen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx,gy = grad(x)\n",
    "\n",
    "# estos son los elementos cuya media en un entorno forman la matriz de covarianza\n",
    "# que describe el elipsoide de incerticumbre\n",
    "gx2 = gx * gx\n",
    "gy2 = gy * gy\n",
    "xyg = gx * gy\n",
    "\n",
    "fig(12,8); \n",
    "plt.subplot(2,2,1); imshowg(gx2); \n",
    "plt.subplot(2,2,2); imshows(xyg); \n",
    "plt.subplot(2,2,4); imshowg(gy2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media de esos valores en un entorno se puede obtener con un filtro de promediado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx2 = gaussian(3,gx2)\n",
    "sy2 = gaussian(3,gy2)\n",
    "sxy = gaussian(3,xyg)\n",
    "\n",
    "fig(12,8)\n",
    "plt.subplot(2,2,1); imshowg(sx2); plt.title('var x')\n",
    "plt.subplot(2,2,2); imshows(sxy); plt.title('covar x y')\n",
    "plt.subplot(2,2,4); imshowg(sy2); plt.title('var y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imagenes anteriores contienen, en los pixels correspondientes, los 3 elementos distintos de la matriz de covarianza que describe el elipsoide de incertidumbre de los gradientes alrededor de cada pixel. Para detectar \"corners\" necesitamos el menor autovalor. Lo calculamos con la fórmula explícita obtenida mediante cualquier herramienta de cálculo simbólico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expresión anterior de $\\lambda _ {min} $ se puede obtener fácilmente mediante `sympy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym\n",
    "\n",
    "a,b,c = sym.symbols('a b c')\n",
    "\n",
    "m = sym.Matrix( [[a,b]\n",
    "                ,[b,c]] )\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.eigenvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym.init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(m.eigenvals().keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym.init_printing(pretty_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La calculamos en toda la imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmin = sx2 + sy2 - np.sqrt(sx2**2 + sy2**2 + 4*sxy**2 - 2*sx2*sy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshowg(lmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente buscamos los máximos locales del detector y extraemos las coordenadas de cada punto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import maximum_filter\n",
    "\n",
    "# puntos iguales que el máximo local\n",
    "def nms(x, t = 0.1):\n",
    "    m = maximum_filter(x,3)\n",
    "    h = np.max(m)\n",
    "    return (x == m) & (x > t*h)\n",
    "\n",
    "k = nms(lmin,0.01)\n",
    "\n",
    "py,px = np.where(k)\n",
    "\n",
    "fig(12,8)\n",
    "plt.imshow(img); ax = plt.axis();\n",
    "plt.plot(px,py,'.r'); plt.axis(ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este detector está disponible directamente en OpenCV (`goodFeaturesToTrack`). Suele utilizarse para determinar el desplazamiento entre imágenes sucesivas para aplicaciones de *tracking*. El criterio utilizado (que tenga bordes en diferentes direcciones) hace que el punto se pueda localizar con mucha precisión en diferentes imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = rgb2gray(img)\n",
    "\n",
    "corners = cv.goodFeaturesToTrack(g, maxCorners=100, qualityLevel=0.01, minDistance=10)\n",
    "\n",
    "print(corners.shape)\n",
    "\n",
    "corners = corners.reshape(corners.shape[0],2)\n",
    "\n",
    "fig(12,8)\n",
    "plt.imshow(img); ax = plt.axis('off');\n",
    "plt.plot(corners[:,0],corners[:,1],'.r'); plt.axis(ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Point tracking*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejemplo de código [`lk_track.py`](../code/lk_track.py) muestra la detección y seguimiento de puntos destacados para estimar el [flujo óptico](https://en.wikipedia.org/wiki/Optical_flow).\n",
    "\n",
    "![tracks.png](https://raw.githubusercontent.com/albertoruiz/umucv/master/images/demos/tracks.png)\n",
    "\n",
    "En este caso es un flujo *sparse*, disponible solo en los puntos detectados. (La obtención de flujo denso requiere mucho mayor esfuerzo computacional.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra una prueba de concepto del método de [Lucas-Kanade](https://en.wikipedia.org/wiki/Lucas%E2%80%93Kanade_method) para calcular el flujo óptico.\n",
    "\n",
    "Para ello usaremos como ejemplo un \"punto difuso\" que se desplaza a una velocidad que suponemos desconocida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.arange(30)\n",
    "x,y = np.meshgrid(r,r)\n",
    "\n",
    "vx,vy = 1,3\n",
    "\n",
    "def f(x,y,t):\n",
    "    return np.exp(-0.5*((x-15-vx*t)**2+(y-15-vy*t)**2)/10)\n",
    "\n",
    "fig(12,4)\n",
    "plt.subplot(1,3,1); plt.imshow(f(x,y,0),'gray'); plt.axis('off'); plt.title('t=0')\n",
    "plt.subplot(1,3,2); plt.imshow(f(x,y,1),'gray'); plt.axis('off'); plt.title('t=1');\n",
    "plt.subplot(1,3,3); plt.imshow(f(x,y,2),'gray'); plt.axis('off'); plt.title('t=2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro objetivo es deducir \"directamente\" la velocidad de esta mancha, sin explorar todas las posibles localizaciones en el frame siguiente.\n",
    "\n",
    "En el caso unidimensional la secuencia de imágenes puede modelarse localmente como una forma constante $g$ que se desplaza:\n",
    "\n",
    "$$f(x,t) = g(x-vt)$$\n",
    "\n",
    "Una forma de \"despejar\" la velocidad es tomar derivadas parciales:\n",
    "\n",
    "$$f_x \\equiv \\frac{\\partial f(x,t)} {\\partial x} = g'(x-vt) \\hspace{4em}\n",
    "f_t \\equiv \\frac{\\partial f(x,t)} {\\partial t} = g'(x-vt) \\;(-v)$$\n",
    "\n",
    "Por tanto:\n",
    "\n",
    "$$v = \\frac{-f_t }{f_x}$$\n",
    "\n",
    "\n",
    "El caso bidimensional es más interesante:\n",
    "\n",
    "$$f(x,y,t) = g(x-v_x t\\,,\\, y-v_y t)$$\n",
    "\n",
    "$$\\frac{\\partial f(x,y,t)} {\\partial x} = \\frac{\\partial g(x-v_x t \\,,\\, y-v_y t)}{\\partial x}$$\n",
    "\n",
    "$$\\frac{\\partial f(x,y,t)} {\\partial y} = \\frac{\\partial g(x-v_x t\\,,\\, y-v_y t)}{\\partial y}$$\n",
    "\n",
    "$$\\frac{\\partial f(x,y,t)} {\\partial t} = -v_x \\frac{\\partial g(x-v_x t \\,,\\, y-v_y t)}{\\partial x} -v_y \\frac{\\partial g(x-v_x t\\,,\\, y-v_y t)}{\\partial y} = - v \\cdot \\nabla f(x,y,t) $$\n",
    "\n",
    "Ahora las derivadas en cada punto no determinan unívocamente la velocidad $v = (v_x,v_y)$, sino que imponen una restricción a sus componentes. Es necesario resolver un sistema agrupando las ecuaciones correspondientes a un pequeño entorno de cada punto. (Bastarían dos, pero se usan más para ganar robustez.) El sistema tendrá solución única en las zonas con varias direcciones de gradiente.\n",
    "\n",
    "En la práctica, las derivadas parciales se aproximan mediante diferencias finitas (o convolución con máscaras de Sobel) y diferencias entre frames consecutivos. Por tanto, la precisión será mayor cuanto menor sea la velocidad en pixels/frame. De ahí la necesidad de crear una pirámide de escalas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos una aproximación a las derivadas parciales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    vx,vy = 1,3\n",
    "    ht = h = 0.001\n",
    "else:\n",
    "    vx, vy = 0.2,0.7\n",
    "    h = 1; ht = 1\n",
    "\n",
    "dx = (f(x+h,y,0) - f(x,y,0))/h\n",
    "dy = (f(x,y+h,0) - f(x,y,0))/h\n",
    "dt = (f(x,y,0+ht) - f(x,y,0))/ht\n",
    "\n",
    "fig(12,4)\n",
    "plt.subplot(1,3,1); plt.imshow(dx,'gray'); plt.axis('off'); plt.title('$\\partial f / \\partial x$')\n",
    "plt.subplot(1,3,2); plt.imshow(dy,'gray'); plt.axis('off'); plt.title('$\\partial f / \\partial y$');\n",
    "plt.subplot(1,3,3); plt.imshow(dt,'gray'); plt.axis('off'); plt.title('$\\partial f / \\partial t$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos las derivadas en trozos 3x3 en los que resolveremos el [sistema sobredeterminado](sistecs.ipynb) (9 ecuaciones y 2 incógnitas) por mínimos cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(img,sz):\n",
    "    r,c = img.shape\n",
    "    return np.array([np.split(x, c//sz, axis=1) for x in np.split(img,r//sz)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx  = split(x,3)\n",
    "ty  = split(y,3)\n",
    "tdx = split(dx,3)\n",
    "tdy = split(dy,3)\n",
    "tdt = split(dt,3)\n",
    "\n",
    "r = []\n",
    "for i in range(len(tx)):\n",
    "    for j in range(len(tx[0])):\n",
    "        ddx = tdx[i,j].reshape(-1,1)\n",
    "        ddy = tdy[i,j].reshape(-1,1)\n",
    "        ddt = tdt[i,j].reshape(-1)\n",
    "        A = np.hstack([-ddx,-ddy])\n",
    "        B = ddt\n",
    "        (vx,vy), _, _,sv = np.linalg.lstsq(A,B,rcond=None)\n",
    "        r.append((tx[i,j,1,1],ty[i,j,1,1], vx, vy, sv.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero solo representamos la solución en las posiciones donde el sistema está bien condicionado (el menor valor singular debe ser suficientemente grande). Esto ocurre cuando hay un gradiente apreciable en dos direcciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx,cy,qx,qy,s = np.array(r).T\n",
    "ok = s > 1e-3\n",
    "fig(6,6)\n",
    "plt.quiver(cx[ok], cy[ok], qx[ok], -qy[ok], color='Red',\n",
    "           width=0.003, scale=1, scale_units='xy');\n",
    "plt.axis([0,30,30,0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estimación de la velocidad es bastante precisa cuando la velocidad es inferior a 1 pixel/frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qx[ok].mean(), qy[ok].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiando los valores de vx, vy, h, y ht más arriba se puede estudiar el punto de ruptura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de Lucas-Kanade admite transformaciones de dominio más generales que pueden incluir escalados, rotaciones, e incluso deformaciones de perspectiva. Su variante [composicional inversa](https://www.ri.cmu.edu/pub_files/pub4/baker_simon_2004_2/baker_simon_2004_2.pdf) es particularlmente eficiente."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
